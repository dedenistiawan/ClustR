# Algoritma K-Means {#km}

```{=html}
<style>
body{
text-align: justify}
</style>
```

```{r, child="_setup.Rmd"}
```

Algoritma K-Means merupakan salah satu metode yang paling populer dalam analisis *cluster*, yang digunakan untuk mengelompokkan data ke dalam beberapa kelompok berdasarkan kesamaan fitur [@jain2010] . Metode ini bekerja dengan cara membagi data ke dalam $K$ cluster, di mana $K$ adalah jumlah *cluster* yang ditentukan sebelumnya oleh pengguna [@macqueen1967some]. Proses pengelompokan ini dilakukan dengan meminimalkan jarak antara data dalam satu *cluster* dan pusat *cluster* (centroid) yang dihasilkan. Langkah pertama dalam algoritma K-Means adalah inisialisasi centroid untuk setiap *cluster*, yang dapat dilakukan secara acak atau menggunakan metode tertentu seperti K-Means++ [@arthur2007kmeans]. Setelah centroid diinisialisasi, algoritma kemudian mengelompokkan setiap data ke dalam *cluster* terdekat berdasarkan jarak Euclidean[@hastie2009elements]. Proses ini diulang hingga tidak ada perubahan signifikan dalam posisi *centroid* atau tidak ada perubahan dalam pengelompokan data.

Salah satu keunggulan dari algoritma K-Means adalah kesederhanaannya, yang membuatnya mudah dipahami dan diimplementasikan, bahkan oleh pemula [@han2011data]. Namun, algoritma ini juga memiliki beberapa kelemahan, seperti ketergantungan pada pemilihan jumlah *cluster* $K$ yang tepat dan sensitivitas terhadap *outlier*. Oleh karena itu, pemilihan $K$ yang optimal sering kali menjadi tantangan tersendiri dalam penerapan algoritma ini [@elbow1975outline]. Dalam praktiknya, algorima K-Means banyak digunakan dalam berbagai bidang, termasuk pemasaran, pengenalan pola, dan analisis citra [@xu2005survey]. Misalnya, dalam pemasaran, K-Means dapat digunakan untuk segmentasi pelanggan berdasarkan perilaku pembelian mereka, sehingga perusahaan dapat menargetkan strategi pemasaran yang lebih efektif [@kumar2016creating]. Dengan demikian, pemahaman yang baik tentang algoritma K-Means sangat penting bagi para peneliti dan praktisi yang ingin menerapkan analisis *cluster* dalam pekerjaan mereka.

Secara keseluruhan, algoritma K-Means adalah alat yang kuat dan fleksibel untuk analisis *cluster*, meskipun penggunaannya memerlukan pemahaman yang mendalam tentang data dan konteks analisis [@bishop2006pattern]. Dalam buku ini, kami akan membahas secara rinci tentang cara menerapkan algoritma K-Means menggunakan `r ttcode("R")`, serta memberikan panduan langkah demi langkah untuk membantu pemula memahami dan menguasai teknik ini. Dengan demikian, diharapkan pembaca dapat memanfaatkan algoritma K-Means dalam analisis data mereka secara efektif.

## Tahapan Algoritma K-Means

```{=html}
<style>
body{
text-align: justify}
</style>
```

### 1. Inisialisasi Centroid {-}
Pilih jumlah cluster $K$ yang diinginkan. Inisialisasi $K$ centroid secara acak dari dataset. Centroid adalah titik yang mewakili pusat dari setiap cluster.

$$
C_k = (x_{k1}, x_{k2}, \ldots, x_{kn}) \quad \text{untuk } k = 1, 2, \ldots, K
$$
di mana $C_k$ adalah centroid untuk cluster ke-$k$ dan $x_{ki}$ adalah nilai fitur ke-$i$ dari centroid ke-$k$.

### 2. Penugasan Cluster {-}
Untuk setiap titik data $x_i$, hitung jarak ke setiap centroid $C_k$ dan tetapkan titik data tersebut ke cluster dengan centroid terdekat. Jarak yang umum digunakan adalah jarak Euclidean.

$$
d(x_i, C_k) = \sqrt{\sum_{j=1}^{m} (x_{ij} - C_{kj})^2}
$$
di mana $d(x_i, C_k)$ adalah jarak antara titik data $x_i$ dan centroid $C_k$, $m$ adalah jumlah fitur, dan $x_{ij}$ adalah nilai fitur ke-$j$ dari titik data ke-$i$.

Penugasan cluster dapat dinyatakan sebagai:

$$
\text{Cluster}(x_i) = \arg\min_{k} d(x_i, C_k)
$$

### 3. Perbaharui Centroid {-}
Setelah semua titik data ditugaskan ke cluster, hitung ulang posisi centroid untuk setiap cluster dengan mengambil rata-rata dari semua titik data yang ditugaskan ke cluster tersebut.

$$
C_k = \frac{1}{N_k} \sum_{x_i \in \text{Cluster}_k} x_i
$$
di mana $N_k$ adalah jumlah titik data dalam cluster ke-$k$ dan $\text{Cluster}_k$ adalah himpunan titik data yang ditugaskan ke cluster ke-$k$.

### 4. Ulangi Langkah 2 dan 3 {-}
Ulangi langkah penugasan cluster dan pembaruan centroid hingga tidak ada perubahan signifikan dalam posisi centroid atau tidak ada perubahan dalam pengelompokan data. Kriteria konvergensi dapat berupa:

$$
\text{Jika } \| C_k^{(t)} - C_k^{(t-1)} \| < \epsilon \quad \text{atau tidak ada perubahan cluster}
$$
di mana $\epsilon$ adalah ambang batas kecil yang ditentukan sebelumnya.

### 5. Hasil Akhir {-}
Setelah konvergensi tercapai, hasil akhir adalah centroid dari setiap cluster dan pengelompokan titik data ke dalam cluster yang sesuai.

```{r, eval = my_output == "html", results='asis', echo=FALSE, purl=FALSE}
cat('
<div class = "keyconcept" <div class = "keyconcept" id="KC2.1"> 
<h3 class = "right"> </h3> 
<h3 class= "left"> Ringkasan </h3> 

<p> Algoritma K-Means adalah metode iteratif yang mengelompokkan data ke dalam $K$ cluster berdasarkan kesamaan fitur. Proses ini melibatkan inisialisasi centroid, penugasan titik data ke cluster terdekat, dan pembaruan centroid hingga konvergensi tercapai. Dengan menggunakan rumus jarak Euclidean dan rata-rata, algoritma ini dapat dengan efektif mengelompokkan data dalam berbagai aplikasi analisis data.

</p> 
</div>')
```

## Eksperimen Algoritma K-Means

```{=html}
<style>
body{
text-align: justify}
</style>
```

### Deskripsi Data {.unnumbered}

Data yang digunakan dalam eksperimen k-means ini berasal dari Tim Percepatan Penanggulangan Kemiskinan [(TNP2K)](https://www.tnp2k.go.id/). TNP2K merupakan lembaga yang bertugas untuk merumuskan dan melaksanakan kebijakan serta program penanggulangan kemiskinan di Indonesia. Data yang diperoleh mencakup berbagai variabel yang relevan untuk analisis kemiskinan, termasuk indikator sosial, ekonomi, dan demografis. Penggunaan data ini bertujuan untuk mengidentifikasi pola dan kelompok dalam populasi yang berpotensi mengalami kemiskinan, sehingga dapat membantu dalam merumuskan strategi yang lebih efektif dalam penanggulangan kemiskinan. Melalui metode k-means, kami berharap dapat menemukan segmentasi yang jelas dalam data, yang pada gilirannya dapat memberikan wawasan yang lebih mendalam mengenai karakteristik kelompok-kelompok yang rentan terhadap kemiskinan.

### Data {.unnumbered}

Dengan menggunakan fungsi `read.csv()` dari R, kami dapat mengimpor data langsung dari URL tersebut ke dalam lingkungan kerja R. Berikut adalah kode yang digunakan untuk membaca data:
Package `reader` menyiapkan fungsi [`read_csv()`](https://readr.tidyverse.org/reference/read_delim.html) untuk import data dari file CSV. Pada kasus ini digunakan data [Data 40% Kemiskinan di jawa Tengah](https://github.com/dedenistiawan/Dataset/blob/main/BDT.csv).

```{r Load_data_km,warning=FALSE, tidy=FALSE}
library (readr)
urlfile = "https://bit.ly/3VO3kRE"
data<-read.csv(url(urlfile), row.names = "Kabupaten")
```

```{r nice-tab-1, tidy=FALSE, echo=FALSE}
knitr::kable(
  head(data, 10), caption = 'Basis Data Terpadu Jawa Tengah',
  booktabs = TRUE)
```

### Memeriksa *Missing Value* {.unnumbered}
Sebelum melakukan analisis cluster menggunakan metode k-means, penting untuk memeriksa apakah terdapat nilai yang hilang (missing values) dalam dataset. Nilai yang hilang dapat mempengaruhi hasil analisis dan interpretasi data, sehingga perlu ditangani dengan tepat. Kami akan menggunakan fungsi `is.na()` dan `colsum()` untuk menghitung jumlah nilai yang hilang dalam setiap kolom dari dataset. Jika ditemukan nilai yang hilang, langkah selanjutnya adalah memutuskan bagaimana cara menanganinya, apakah dengan menghapus baris yang mengandung nilai hilang, mengganti nilai hilang dengan rata-rata, median, atau metode imputasi lainnya.

Berikut adalah kode untuk memeriksa nilai yang hilang dalam dataset:

```{r }
colSums(is.na(data))
```

Setelah melakukan pemeriksaan terhadap dataset, tidak ada nilai yang hilang (*missing values*) dalam data yang kami gunakan. Hal ini penting karena keberadaan nilai yang hilang dapat mempengaruhi hasil analisis dan interpretasi data.

### Visualisasi Matriks jarak {.unnumbered}

Setelah mempersiapkan data dan memastikan tidak ada nilai yang hilang, langkah selanjutnya adalah membuat visualisasi matriks jarak. Visualisasi ini penting untuk memahami seberapa dekat atau jauh objek-objek dalam dataset berdasarkan variabel yang ada. Dengan menggunakan matriks jarak, kita dapat melihat pola dan hubungan antar data yang akan membantu dalam analisis *cluster*. Kami akan menggunakan library `factoextra` untuk menghitung dan memvisualisasikan matriks jarak. Fungsi `get_dist()` akan digunakan untuk menghitung jarak antar objek, dan `fviz_dist()` dari `factoextra` akan digunakan untuk membuat visualisasi. Berikut adalah kode untuk membuat visualisasi matriks jarak:

```{r warning=FALSE, message=FALSE, fig.cap='Matrik Jarak', out.width='80%', fig.asp=.75, fig.align='center'}
#Plot Disatance
library(ggplot2)
library(factoextra)
distance <- get_dist(data)
fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
```

Setelah membuat visualisasi matriks jarak, kita dapat melakukan analisis untuk memahami pola dan hubungan antar objek dalam dataset. Matriks jarak memberikan informasi tentang seberapa mirip atau berbeda objek-objek dalam data berdasarkan variabel yang digunakan.

Dalam visualisasi matriks jarak yang telah dibuat, kita dapat mengamati beberapa hal:

1. **Warna dan Jarak**: 
Warna yang lebih gelap menunjukkan jarak yang lebih dekat antara objek, sedangkan warna yang lebih terang menunjukkan jarak yang lebih jauh. Dengan demikian, objek-objek yang memiliki warna serupa cenderung memiliki karakteristik yang lebih mirip.
   
2. **Kelompok Objek**:
Dari visualisasi, kita dapat mengidentifikasi kelompok objek yang mungkin memiliki kesamaan. Misalnya, jika terdapat beberapa objek yang berdekatan dan memiliki warna yang sama, ini menunjukkan bahwa mereka mungkin termasuk dalam cluster yang sama.

3. **Outlier**:
Objek yang jauh dari kelompok lainnya dapat dianggap sebagai outlier. Outlier ini mungkin memiliki karakteristik yang unik atau berbeda dari mayoritas data, dan perlu dianalisis lebih lanjut untuk memahami penyebab perbedaannya.

Selanjutnya, kita dapat melanjutkan dengan analisis cluster menggunakan algoritma k-means untuk mengelompokkan objek-objek dalam dataset berdasarkan jarak yang telah dihitung. Dengan demikian, kita dapat lebih memahami pola dalam data dan membuat keputusan yang lebih baik berdasarkan hasil analisis.

### Estimasi Jumlah *Cluster* Optimal {.unnumbered}

Dalam metode k-means banyaknya klaster ditentukan sendiri oleh pengguna. Maka dari itu perlu dicari jumlah klaster yang optimum yang dapat mengelompokkan objek dengan baik (Perlu diketahui bahwa metode ini relatif subjektif). Salah satu metode yang digunakan adalah Elbow Plot. Elbow Plot merupakan plot antara banyak klaster dengan total within-cluster variation (total dari simpangan per kluster). Banyak klaster yang dipilih adalah bagian “siku” atau titik dimana terdapat penurunan yang tajam sebelum titik tersebut dan disusul penurunan yang tidak tajam setelah titik tersebut. Hal ini karena penambahan jumlah klaster tidak membawa pengaruh banyak atas variasi yang ada di dalam klaster tersebut.

### Metode Elbow {.unnumbered}

Metode Elbow merupakan suatu metode yang digunakan untuk menghasilkan informasi dalam menentukan jumlah cluster terbaik dengan cara melihat persentase hasil perbandingan antara jumlah cluster yang akan membentuk siku pada suatu titik. Metode ini memberikan ide/gagasan dengan cara memilih nilai cluster dan kemudian menambah nilai cluster tersebut untuk dijadikan model data dalam penentuan cluster terbaik. Dan selain itu persentase perhitungan yang dihasilkan menjadi pembanding antara jumlah cluster yang ditambah. Hasil persentase yang berbeda dari setiap nilai cluster dapat ditunjukan dengan menggunakan grafik sebagai sumber informasinya. Jika nilai cluster pertama dengan nilai cluster kedua memberikan sudut dalam grafik atau nilainya mengalami penurunan paling besar maka nilai cluster tersebut yang terbaik.

```{r fig.cap='Plot Jumlah Cluster Metode Elbow', out.width='80%', fig.asp=.75, fig.align='center'}
#penentuan jumlah cluster optimal
library(ggplot2)
library(factoextra)
fviz_nbclust(data, kmeans, method = "wss") +
  geom_vline(xintercept = 2, linetype = 2)
```

Metode elbow menggunakan nilai total wss (whitin sum square) sebagai penentu 𝐾 optimalnya. Dari gambar di atas terlihat garis mengalami patahan yang membentuk elbow atau siku pada saat 𝐾 = 2. Maka dengan menggunakan metode ini diperoleh 𝐾 optimal pada saat berada di 𝐾 = 2.

### Metode Silhouette {.unnumbered}

Silhouette Coefficient digunakan untuk melihat kualitas dan kekuatan cluster, seberapa baik suatu objek ditempatkan dalam suatu cluster. Metode ini merupakan gabungan dari metode cohesion dan separation.

```{r fig.cap='Plot Jumlah Cluster Metode silhouette', out.width='80%', fig.asp=.75, fig.align='center'}
##Average Silhouette Method
fviz_nbclust(data, kmeans, method = "silhouette")
```

Pendekatan rata-rata nilai metode silhouette untuk menduga kualitas dari klaster yang terbentuk. Semakin tinggi nilai rata-ratanya maka akan semakin baik. Berdasarkan grafik pada gambar di atas banyak klaster optimal yang terbentuk pada 𝐾 = 2.

### Membuat Plot *Cluster* {.unnumbered}

Jumlah klaster yang dibentuk mulai dari 2 sampai 5, untuk melihat sebaran data pada masing-masing *cluster*

```{r}
#gunakan beberapa nilai K
k2 <- kmeans(data, centers = 2, nstart = 25)
k3 <- kmeans(data, centers = 3, nstart = 25)
k4 <- kmeans(data, centers = 4, nstart = 25)
k5 <- kmeans(data, centers = 5, nstart = 25)
```

```{r}
# komparasi plot
p1 <- fviz_cluster(k2, geom = "point", data = data) + ggtitle("k = 2")
p2 <- fviz_cluster(k3, geom = "point",  data = data) + ggtitle("k = 3")
p3 <- fviz_cluster(k4, geom = "point",  data = data) + ggtitle("k = 4")
p4 <- fviz_cluster(k5, geom = "point",  data = data) + ggtitle("k = 5")
```

```{r warning=FALSE, fig.cap='Plot Jumlah Cluster', out.width='80%', fig.asp=.75, fig.align='center'}
library(gridExtra)
grid.arrange(p1, p2, p3, p4, nrow = 2)
```

### Eksperimen K-Means Clustering {.unnumbered}

Dari pendekatan metode elbow dan metode Silhouette di dapatkan jumlah *cluster* optimal adalah K=2. setelah ini dilakukan eksperimen jumlah K=2

```{r}
#jalankan k-means dengan k = 2
set.seed(123)
km.res <- kmeans(data, 2, nstart = 25)
# cetak hasil
print(km.res)
```

Melihat hasil *cluster* akhir pada setiap kabupaten

```{r}
# Jumlah anggota cluster
km.res$cluster
```

Melihat jumlah anggota *cluster*

```{r}
# ukuran cluster
km.res$size
```

### Visualisasi Hasil *clustering* {.unnumbered}

```{r warning=FALSE, fig.cap='Plot Hasil Cluster', out.width='80%', fig.asp=.75, fig.align='center'}
km.res$centers
fviz_cluster(km.res, data = data)
```

```{r fig.cap='Plot Hasil Cluster', out.width='80%', fig.asp=.75, fig.align='center'}
fviz_cluster(km.res, data = data,
             palette = c("#FC4E07", "#00AFBB"),
             ellipse.type = "euclid", 
             star.plot = TRUE, 
             repel = TRUE, 
             ggtheme = theme_minimal())
```


