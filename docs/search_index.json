[["2-km.html", "2 Algoritma K-Means", " 2 Algoritma K-Means body{ text-align: justify} Algoritma K-Means merupakan salah satu metode yang paling populer dalam analisis cluster, yang digunakan untuk mengelompokkan data ke dalam beberapa kelompok berdasarkan kesamaan fitur (Jain 2010) . Metode ini bekerja dengan cara membagi data ke dalam \\(K\\) cluster, di mana \\(K\\) adalah jumlah cluster yang ditentukan sebelumnya oleh pengguna (MacQueen 1967). Proses pengelompokan ini dilakukan dengan meminimalkan jarak antara data dalam satu cluster dan pusat cluster (centroid) yang dihasilkan. Langkah pertama dalam algoritma K-Means adalah inisialisasi centroid untuk setiap cluster, yang dapat dilakukan secara acak atau menggunakan metode tertentu seperti K-Means++ (Arthur and Vassilvitskii 2007). Setelah centroid diinisialisasi, algoritma kemudian mengelompokkan setiap data ke dalam cluster terdekat berdasarkan jarak Euclidean(Hastie, Tibshirani, and Friedman 2009). Proses ini diulang hingga tidak ada perubahan signifikan dalam posisi centroid atau tidak ada perubahan dalam pengelompokan data. Salah satu keunggulan dari algoritma K-Means adalah kesederhanaannya, yang membuatnya mudah dipahami dan diimplementasikan, bahkan oleh pemula (Han, Kamber, and Pei 2011). Namun, algoritma ini juga memiliki beberapa kelemahan, seperti ketergantungan pada pemilihan jumlah cluster \\(K\\) yang tepat dan sensitivitas terhadap outlier. Oleh karena itu, pemilihan \\(K\\) yang optimal sering kali menjadi tantangan tersendiri dalam penerapan algoritma ini (Elbow 1975). Dalam praktiknya, algorima K-Means banyak digunakan dalam berbagai bidang, termasuk pemasaran, pengenalan pola, dan analisis citra (Xu and Wunsch 2005). Misalnya, dalam pemasaran, K-Means dapat digunakan untuk segmentasi pelanggan berdasarkan perilaku pembelian mereka, sehingga perusahaan dapat menargetkan strategi pemasaran yang lebih efektif (Kumar and Reinartz 2016). Dengan demikian, pemahaman yang baik tentang algoritma K-Means sangat penting bagi para peneliti dan praktisi yang ingin menerapkan analisis cluster dalam pekerjaan mereka. Secara keseluruhan, algoritma K-Means adalah alat yang kuat dan fleksibel untuk analisis cluster, meskipun penggunaannya memerlukan pemahaman yang mendalam tentang data dan konteks analisis (Bishop 2006). Dalam buku ini, kami akan membahas secara rinci tentang cara menerapkan algoritma K-Means menggunakan R, serta memberikan panduan langkah demi langkah untuk membantu pemula memahami dan menguasai teknik ini. Dengan demikian, diharapkan pembaca dapat memanfaatkan algoritma K-Means dalam analisis data mereka secara efektif. References Arthur, David, and Sergei Vassilvitskii. 2007. “K-Means++: The Advantages of Careful Seeding.” In Proceedings of the Eighteenth Annual ACM-SIAM Symposium on Discrete Algorithms, 1027–35. Bishop, Christopher M. 2006. Pattern Recognition and Machine Learning. Springer. Elbow, W. 1975. “Outline for a New Approach to Unsupervised Clustering.” In Proceedings of the 5th Annual Conference on Statistical Computing, 1–5. Han, Jia, Micheline Kamber, and Jian Pei. 2011. Data Mining: Concepts and Techniques. Morgan Kaufmann. Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2009. The Elements of Statistical Learning: Data Mining, Inference, and Prediction. Springer. Jain, Anil K. 2010. “Data Clustering: 50 Years Beyond K-Means.” Pattern Recognition Letters 31 (8): 651–66. https://doi.org/10.1016/j.patrec.2009.09.011. Kumar, V., and W. Reinartz. 2016. “Creating Enduring Customer Value.” Journal of Marketing 80 (6): 36–68. MacQueen, J. 1967. “Some Methods for Classification and Analysis of Multivariate Observations.” In Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, 1:281–97. Xu, Rui, and Donald Wunsch. 2005. “Survey of Clustering Algorithms.” IEEE Transactions on Neural Networks 16 (3): 645–78. "],["2.1-tahapan-algoritma-k-means.html", "2.1 Tahapan Algoritma K-Means", " 2.1 Tahapan Algoritma K-Means body{ text-align: justify} 1. Inisialisasi Centroid Pilih jumlah cluster \\(K\\) yang diinginkan. Inisialisasi \\(K\\) centroid secara acak dari dataset. Centroid adalah titik yang mewakili pusat dari setiap cluster. \\[ C_k = (x_{k1}, x_{k2}, \\ldots, x_{kn}) \\quad \\text{untuk } k = 1, 2, \\ldots, K \\] di mana \\(C_k\\) adalah centroid untuk cluster ke-\\(k\\) dan \\(x_{ki}\\) adalah nilai fitur ke-\\(i\\) dari centroid ke-\\(k\\). 2. Penugasan Cluster Untuk setiap titik data \\(x_i\\), hitung jarak ke setiap centroid \\(C_k\\) dan tetapkan titik data tersebut ke cluster dengan centroid terdekat. Jarak yang umum digunakan adalah jarak Euclidean. \\[ d(x_i, C_k) = \\sqrt{\\sum_{j=1}^{m} (x_{ij} - C_{kj})^2} \\] di mana \\(d(x_i, C_k)\\) adalah jarak antara titik data \\(x_i\\) dan centroid \\(C_k\\), \\(m\\) adalah jumlah fitur, dan \\(x_{ij}\\) adalah nilai fitur ke-\\(j\\) dari titik data ke-\\(i\\). Penugasan cluster dapat dinyatakan sebagai: \\[ \\text{Cluster}(x_i) = \\arg\\min_{k} d(x_i, C_k) \\] 3. Perbaharui Centroid Setelah semua titik data ditugaskan ke cluster, hitung ulang posisi centroid untuk setiap cluster dengan mengambil rata-rata dari semua titik data yang ditugaskan ke cluster tersebut. \\[ C_k = \\frac{1}{N_k} \\sum_{x_i \\in \\text{Cluster}_k} x_i \\] di mana \\(N_k\\) adalah jumlah titik data dalam cluster ke-\\(k\\) dan \\(\\text{Cluster}_k\\) adalah himpunan titik data yang ditugaskan ke cluster ke-\\(k\\). 4. Ulangi Langkah 2 dan 3 Ulangi langkah penugasan cluster dan pembaruan centroid hingga tidak ada perubahan signifikan dalam posisi centroid atau tidak ada perubahan dalam pengelompokan data. Kriteria konvergensi dapat berupa: \\[ \\text{Jika } \\| C_k^{(t)} - C_k^{(t-1)} \\| &lt; \\epsilon \\quad \\text{atau tidak ada perubahan cluster} \\] di mana \\(\\epsilon\\) adalah ambang batas kecil yang ditentukan sebelumnya. 5. Hasil Akhir Setelah konvergensi tercapai, hasil akhir adalah centroid dari setiap cluster dan pengelompokan titik data ke dalam cluster yang sesuai. Ringkasan Algoritma K-Means adalah metode iteratif yang mengelompokkan data ke dalam \\(K\\) cluster berdasarkan kesamaan fitur. Proses ini melibatkan inisialisasi centroid, penugasan titik data ke cluster terdekat, dan pembaruan centroid hingga konvergensi tercapai. Dengan menggunakan rumus jarak Euclidean dan rata-rata, algoritma ini dapat dengan efektif mengelompokkan data dalam berbagai aplikasi analisis data. "],["2.2-eksperimen-algoritma-k-means.html", "2.2 Eksperimen Algoritma K-Means", " 2.2 Eksperimen Algoritma K-Means body{ text-align: justify} Deskripsi Data Data yang digunakan dalam eksperimen k-means ini berasal dari Tim Percepatan Penanggulangan Kemiskinan (TNP2K). TNP2K merupakan lembaga yang bertugas untuk merumuskan dan melaksanakan kebijakan serta program penanggulangan kemiskinan di Indonesia. Data yang diperoleh mencakup berbagai variabel yang relevan untuk analisis kemiskinan, termasuk indikator sosial, ekonomi, dan demografis. Penggunaan data ini bertujuan untuk mengidentifikasi pola dan kelompok dalam populasi yang berpotensi mengalami kemiskinan, sehingga dapat membantu dalam merumuskan strategi yang lebih efektif dalam penanggulangan kemiskinan. Melalui metode k-means, kami berharap dapat menemukan segmentasi yang jelas dalam data, yang pada gilirannya dapat memberikan wawasan yang lebih mendalam mengenai karakteristik kelompok-kelompok yang rentan terhadap kemiskinan. Data Dengan menggunakan fungsi read.csv() dari R, kami dapat mengimpor data langsung dari URL tersebut ke dalam lingkungan kerja R. Berikut adalah kode yang digunakan untuk membaca data: Package reader menyiapkan fungsi read_csv() untuk import data dari file CSV. Pada kasus ini digunakan data Data 40% Kemiskinan di jawa Tengah. library (readr) urlfile = &quot;https://bit.ly/3VO3kRE&quot; data&lt;-read.csv(url(urlfile), row.names = &quot;Kabupaten&quot;) Tabel 2.1: Basis Data Terpadu Jawa Tengah X1 X2 X3 X4 X5 X6 X7 X8 X9 X10 CILACAP 5.19 5.67 5.08 5.44 5.22 6.05 11.47 9.78 5.55 5.12 BANYUMAS 5.71 4.47 5.18 5.51 5.02 6.21 7.39 6.96 5.98 8.22 PURBALINGGA 3.30 2.19 3.80 3.13 3.73 3.34 8.71 7.41 3.21 4.65 BANJARNEGARA 2.73 2.34 3.76 2.80 2.57 2.99 3.31 5.45 4.21 6.05 KEBUMEN 4.17 2.55 3.26 4.16 3.15 4.15 4.30 9.29 4.61 4.34 PURWOREJO 1.87 2.12 1.48 3.05 1.78 1.83 5.00 4.90 3.12 2.09 WONOSOBO 2.13 1.95 3.00 1.78 1.62 2.06 0.45 2.32 3.57 0.84 MAGELANG 3.95 3.01 4.22 4.15 3.01 3.64 1.44 3.35 5.69 3.67 BOYOLALI 2.19 3.07 1.61 2.74 2.11 1.82 1.71 2.34 3.41 1.55 KLATEN 3.84 5.15 1.93 4.64 4.04 3.78 8.71 4.45 3.99 3.09 Memeriksa Missing Value Sebelum melakukan analisis cluster menggunakan metode k-means, penting untuk memeriksa apakah terdapat nilai yang hilang (missing values) dalam dataset. Nilai yang hilang dapat mempengaruhi hasil analisis dan interpretasi data, sehingga perlu ditangani dengan tepat. Kami akan menggunakan fungsi is.na() dan colsum() untuk menghitung jumlah nilai yang hilang dalam setiap kolom dari dataset. Jika ditemukan nilai yang hilang, langkah selanjutnya adalah memutuskan bagaimana cara menanganinya, apakah dengan menghapus baris yang mengandung nilai hilang, mengganti nilai hilang dengan rata-rata, median, atau metode imputasi lainnya. Berikut adalah kode untuk memeriksa nilai yang hilang dalam dataset: colSums(is.na(data)) #&gt; X1 X2 X3 X4 X5 X6 X7 X8 X9 X10 #&gt; 0 0 0 0 0 0 0 0 0 0 Setelah melakukan pemeriksaan terhadap dataset, tidak ada nilai yang hilang (missing values) dalam data yang kami gunakan. Hal ini penting karena keberadaan nilai yang hilang dapat mempengaruhi hasil analisis dan interpretasi data. Visualisasi Matriks jarak Setelah mempersiapkan data dan memastikan tidak ada nilai yang hilang, langkah selanjutnya adalah membuat visualisasi matriks jarak. Visualisasi ini penting untuk memahami seberapa dekat atau jauh objek-objek dalam dataset berdasarkan variabel yang ada. Dengan menggunakan matriks jarak, kita dapat melihat pola dan hubungan antar data yang akan membantu dalam analisis cluster. Kami akan menggunakan library factoextra untuk menghitung dan memvisualisasikan matriks jarak. Fungsi get_dist() akan digunakan untuk menghitung jarak antar objek, dan fviz_dist() dari factoextra akan digunakan untuk membuat visualisasi. Berikut adalah kode untuk membuat visualisasi matriks jarak: #Plot Disatance library(ggplot2) library(factoextra) distance &lt;- get_dist(data) fviz_dist(distance, gradient = list(low = &quot;#00AFBB&quot;, mid = &quot;white&quot;, high = &quot;#FC4E07&quot;)) Gambar 2.1: Matrik Jarak Setelah membuat visualisasi matriks jarak, kita dapat melakukan analisis untuk memahami pola dan hubungan antar objek dalam dataset. Matriks jarak memberikan informasi tentang seberapa mirip atau berbeda objek-objek dalam data berdasarkan variabel yang digunakan. Dalam visualisasi matriks jarak yang telah dibuat, kita dapat mengamati beberapa hal: Warna dan Jarak: Warna yang lebih gelap menunjukkan jarak yang lebih dekat antara objek, sedangkan warna yang lebih terang menunjukkan jarak yang lebih jauh. Dengan demikian, objek-objek yang memiliki warna serupa cenderung memiliki karakteristik yang lebih mirip. Kelompok Objek: Dari visualisasi, kita dapat mengidentifikasi kelompok objek yang mungkin memiliki kesamaan. Misalnya, jika terdapat beberapa objek yang berdekatan dan memiliki warna yang sama, ini menunjukkan bahwa mereka mungkin termasuk dalam cluster yang sama. Outlier: Objek yang jauh dari kelompok lainnya dapat dianggap sebagai outlier. Outlier ini mungkin memiliki karakteristik yang unik atau berbeda dari mayoritas data, dan perlu dianalisis lebih lanjut untuk memahami penyebab perbedaannya. Selanjutnya, kita dapat melanjutkan dengan analisis cluster menggunakan algoritma k-means untuk mengelompokkan objek-objek dalam dataset berdasarkan jarak yang telah dihitung. Dengan demikian, kita dapat lebih memahami pola dalam data dan membuat keputusan yang lebih baik berdasarkan hasil analisis. Estimasi Jumlah Cluster Optimal Dalam metode k-means banyaknya klaster ditentukan sendiri oleh pengguna. Maka dari itu perlu dicari jumlah klaster yang optimum yang dapat mengelompokkan objek dengan baik (Perlu diketahui bahwa metode ini relatif subjektif). Salah satu metode yang digunakan adalah Elbow Plot. Elbow Plot merupakan plot antara banyak klaster dengan total within-cluster variation (total dari simpangan per kluster). Banyak klaster yang dipilih adalah bagian “siku” atau titik dimana terdapat penurunan yang tajam sebelum titik tersebut dan disusul penurunan yang tidak tajam setelah titik tersebut. Hal ini karena penambahan jumlah klaster tidak membawa pengaruh banyak atas variasi yang ada di dalam klaster tersebut. Metode Elbow Metode Elbow merupakan suatu metode yang digunakan untuk menghasilkan informasi dalam menentukan jumlah cluster terbaik dengan cara melihat persentase hasil perbandingan antara jumlah cluster yang akan membentuk siku pada suatu titik. Metode ini memberikan ide/gagasan dengan cara memilih nilai cluster dan kemudian menambah nilai cluster tersebut untuk dijadikan model data dalam penentuan cluster terbaik. Dan selain itu persentase perhitungan yang dihasilkan menjadi pembanding antara jumlah cluster yang ditambah. Hasil persentase yang berbeda dari setiap nilai cluster dapat ditunjukan dengan menggunakan grafik sebagai sumber informasinya. Jika nilai cluster pertama dengan nilai cluster kedua memberikan sudut dalam grafik atau nilainya mengalami penurunan paling besar maka nilai cluster tersebut yang terbaik. #penentuan jumlah cluster optimal library(ggplot2) library(factoextra) fviz_nbclust(data, kmeans, method = &quot;wss&quot;) + geom_vline(xintercept = 2, linetype = 2) Gambar 2.2: Plot Jumlah Cluster Metode Elbow Metode elbow menggunakan nilai total wss (whitin sum square) sebagai penentu  optimalnya. Dari gambar di atas terlihat garis mengalami patahan yang membentuk elbow atau siku pada saat  = 2. Maka dengan menggunakan metode ini diperoleh  optimal pada saat berada di  = 2. Metode Silhouette Silhouette Coefficient digunakan untuk melihat kualitas dan kekuatan cluster, seberapa baik suatu objek ditempatkan dalam suatu cluster. Metode ini merupakan gabungan dari metode cohesion dan separation. ##Average Silhouette Method fviz_nbclust(data, kmeans, method = &quot;silhouette&quot;) Gambar 2.3: Plot Jumlah Cluster Metode silhouette Pendekatan rata-rata nilai metode silhouette untuk menduga kualitas dari klaster yang terbentuk. Semakin tinggi nilai rata-ratanya maka akan semakin baik. Berdasarkan grafik pada gambar di atas banyak klaster optimal yang terbentuk pada  = 2. Membuat Plot Cluster Jumlah klaster yang dibentuk mulai dari 2 sampai 5, untuk melihat sebaran data pada masing-masing cluster #gunakan beberapa nilai K k2 &lt;- kmeans(data, centers = 2, nstart = 25) k3 &lt;- kmeans(data, centers = 3, nstart = 25) k4 &lt;- kmeans(data, centers = 4, nstart = 25) k5 &lt;- kmeans(data, centers = 5, nstart = 25) # komparasi plot p1 &lt;- fviz_cluster(k2, geom = &quot;point&quot;, data = data) + ggtitle(&quot;k = 2&quot;) p2 &lt;- fviz_cluster(k3, geom = &quot;point&quot;, data = data) + ggtitle(&quot;k = 3&quot;) p3 &lt;- fviz_cluster(k4, geom = &quot;point&quot;, data = data) + ggtitle(&quot;k = 4&quot;) p4 &lt;- fviz_cluster(k5, geom = &quot;point&quot;, data = data) + ggtitle(&quot;k = 5&quot;) library(gridExtra) grid.arrange(p1, p2, p3, p4, nrow = 2) Gambar 2.4: Plot Jumlah Cluster Eksperimen K-Means Clustering Dari pendekatan metode elbow dan metode Silhouette di dapatkan jumlah cluster optimal adalah K=2. setelah ini dilakukan eksperimen jumlah K=2 #jalankan k-means dengan k = 2 set.seed(123) km.res &lt;- kmeans(data, 2, nstart = 25) # cetak hasil print(km.res) #&gt; K-means clustering with 2 clusters of sizes 22, 13 #&gt; #&gt; Cluster means: #&gt; X1 X2 X3 X4 X5 X6 X7 X8 #&gt; 1 1.918182 2.017273 1.675000 1.949091 1.890455 1.728182 1.557273 1.286818 #&gt; 2 4.446923 4.276923 4.854615 4.394615 4.494615 4.769231 5.056154 5.515385 #&gt; X9 X10 #&gt; 1 1.952727 1.455455 #&gt; 2 4.389231 5.230000 #&gt; #&gt; Clustering vector: #&gt; CILACAP BANYUMAS PURBALINGGA BANJARNEGARA KEBUMEN #&gt; 2 2 2 2 2 #&gt; PURWOREJO WONOSOBO MAGELANG BOYOLALI KLATEN #&gt; 1 1 2 1 2 #&gt; SUKOHARJO WONOGIRI KARANGANYAR SRAGEN GROBOGAN #&gt; 1 1 1 1 2 #&gt; BLORA REMBANG PATI KUDUS JEPARA #&gt; 1 1 2 1 2 #&gt; DEMAK SEMARANG TEMANGGUNG KENDAL BATANG #&gt; 1 1 1 1 1 #&gt; PEKALONGAN PEMALANG TEGAL BREBES KOTA MAGELANG #&gt; 1 2 2 2 1 #&gt; KOTA SURAKARTA KOTA SALATIGA KOTA SEMARANG KOTA PEKALONGAN KOTA TEGAL #&gt; 1 1 1 1 1 #&gt; #&gt; Within cluster sum of squares by cluster: #&gt; [1] 262.6536 466.0163 #&gt; (between_SS / total_SS = 51.3 %) #&gt; #&gt; Available components: #&gt; #&gt; [1] &quot;cluster&quot; &quot;centers&quot; &quot;totss&quot; &quot;withinss&quot; &quot;tot.withinss&quot; #&gt; [6] &quot;betweenss&quot; &quot;size&quot; &quot;iter&quot; &quot;ifault&quot; Melihat hasil cluster akhir pada setiap kabupaten # Jumlah anggota cluster km.res$cluster #&gt; CILACAP BANYUMAS PURBALINGGA BANJARNEGARA KEBUMEN #&gt; 2 2 2 2 2 #&gt; PURWOREJO WONOSOBO MAGELANG BOYOLALI KLATEN #&gt; 1 1 2 1 2 #&gt; SUKOHARJO WONOGIRI KARANGANYAR SRAGEN GROBOGAN #&gt; 1 1 1 1 2 #&gt; BLORA REMBANG PATI KUDUS JEPARA #&gt; 1 1 2 1 2 #&gt; DEMAK SEMARANG TEMANGGUNG KENDAL BATANG #&gt; 1 1 1 1 1 #&gt; PEKALONGAN PEMALANG TEGAL BREBES KOTA MAGELANG #&gt; 1 2 2 2 1 #&gt; KOTA SURAKARTA KOTA SALATIGA KOTA SEMARANG KOTA PEKALONGAN KOTA TEGAL #&gt; 1 1 1 1 1 Melihat jumlah anggota cluster # ukuran cluster km.res$size #&gt; [1] 22 13 Visualisasi Hasil clustering # Cluster means km.res$centers #&gt; X1 X2 X3 X4 X5 X6 X7 X8 #&gt; 1 1.918182 2.017273 1.675000 1.949091 1.890455 1.728182 1.557273 1.286818 #&gt; 2 4.446923 4.276923 4.854615 4.394615 4.494615 4.769231 5.056154 5.515385 #&gt; X9 X10 #&gt; 1 1.952727 1.455455 #&gt; 2 4.389231 5.230000 fviz_cluster(km.res, data = data) Gambar 2.5: Plot Hasil Cluster fviz_cluster(km.res, data = data, palette = c(&quot;#FC4E07&quot;, &quot;#00AFBB&quot;), ellipse.type = &quot;euclid&quot;, # Concentration ellipse star.plot = TRUE, # Add segments from centroids to items repel = TRUE, # Avoid label overplotting (slow) ggtheme = theme_minimal()) Gambar 2.6: Plot Hasil Cluster "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
