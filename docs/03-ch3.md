# Ukuran Kemiripan dan Ketidakmiripan Data {#simdis}

```{=html}
<style>
body{
text-align: justify}
</style>
```












> "The purpose of data analysis is to understand the structure of the data and learn about the world it represents"
>
> -- William S. Cleveland

Analisis cluster berfokus pada pengelompokan objek yang memiliki kesamaan tertentu ke dalam satu kelompok atau clutser. Tujuannya adalah untuk mengidentifikasi pola atau struktur dalam data dengan cara mengelompokkan objek yang mempunyai kemiripan dan memisahkan objek yang berbeda. Setiap cluster berisi objek-objek yang lebih mirip satu sama lain dibandingkan dengan objek-objek di cluster lainnya [@han2012mining].

Pada bab ini, akan dibahas secara mendalam berbagai ukuran yang digunakan untuk mengukur kemiripan dan ketidakmiripan dalam analisis cluster. Ukuran kemiripan digunakan untuk menilai sejauh mana dua objek atau instansi memiliki karakteristik yang serupa, sementara ukuran ketidakmiripan (atau jarak) digunakan untuk mengukur perbedaan antara objek-objek tersebut. Kedua ukuran ini sangat penting dalam menentukan bagaimana objek-objek tersebut akan dikelompokkan dalam cluster yang sesuai. Pembahasan ini mencakup berbagai metode pengukuran yang sering digunakan dalam analisis klaster, seperti jarak Euclidean, jarak Manhattan, dan ukuran kesamaan berbasis korelasi, serta cara-cara penerapannya dalam berbagai algoritma clustering dengan R.

## Ukuran Kemiripan

```{=html}
<style>
body{
text-align: justify}
</style>
```

Ukuran kemiripan digunakan untuk mengukur tingkat kesamaan antara dua objek dalam ruang vektor berdasarkan atribut atau fitur tertentu. Konsep ini sangat penting dalam berbagai bidang, seperti analisis teks untuk menentukan kesamaan antar dokumen atau kalimat, sistem rekomendasi untuk menyarankan item yang relevan berdasarkan preferensi pengguna, serta dalam analisis cluster untuk mengelompokkan data dengan karakteristik serupa. Berbagai metrik, seperti cosine similarity, Jaccard similarity, dan Euclidean distance, sering digunakan untuk menghitung kemiripan, tergantung pada jenis data dan tujuan analisis.

### Cosine Similarity

Cosine similarity adalah ukuran yang digunakan untuk menentukan seberapa mirip dua vektor dalam ruang multidimensi. Ukuran ini sering digunakan dalam analisis teks dan pengolahan bahasa alami untuk mengukur kesamaan antara dokumen atau kata-kata. Cosine similarity mengukur sudut antara dua vektor, bukan jarak antar vektor, sehingga dapat memberikan hasil yang lebih baik dalam konteks data yang memiliki dimensi tinggi.

Cosine similarity antara dua vektor $A$ dan $B$ didefinisikan dengan rumus:

$$
\text{Cosine Similarity} = \frac{A \cdot B}{\|A\| \|B\|}
$$

Di mana:

-   $A \cdot B$ adalah hasil kali dot (dot product) antara vektor $A$ dan $B$.

-   $\|A\|$ dan $\|B\|$ adalah norma (magnitudo) dari vektor $A$ dan $B$.

Nilai cosine similarity berkisar antara -1 hingga 1:

-   **1**: Vektor identik (sama arah).

-   **0**: Vektor ortogonal (tidak ada kesamaan).

-   **-1**: Vektor berlawanan arah.

Misalkan kita memiliki dua vektor:

-   $A = [1, 2, 3]$

-   $B = [4, 5, 6]$

Langkah-langkah perhitungan cosine similarity adalah sebagai berikut:

**1. Hitung dot product** $A \cdot B$: $$
    A \cdot B = (1 \times 4) + (2 \times 5) + (3 \times 6) = 4 + 10 + 18 = 32
    $$

**2. Hitung norma** $\|A\|$ dan $\|B\|$: $$
    \|A\| = \sqrt{1^2 + 2^2 + 3^2} = \sqrt{1 + 4 + 9} = \sqrt{14}
    $$ $$
    \|B\| = \sqrt{4^2 + 5^2 + 6^2} = \sqrt{16 + 25 + 36} = \sqrt{77}
    $$

**3. Hitung cosine similarity**: $$
    \text{Cosine Similarity} = \frac{32}{\sqrt{14} \times \sqrt{77}} \approx 0.974
    $$

**Contoh Penerapan cosine similarity dengan R**


``` r
# Memuat library yang diperlukan
library(lsa)

# Mendefinisikan vektor A dan B
A <- c(1, 2, 3)
B <- c(4, 5, 6)

# Menghitung dot product
dot_product <- sum(A * B)

# Menghitung norma A dan B
norm_A <- sqrt(sum(A^2))
norm_B <- sqrt(sum(B^2))

# Menghitung cosine similarity
cosine_similarity <- dot_product / (norm_A * norm_B)

# Menampilkan hasil
list(dot_product = dot_product, norm_A = norm_A, norm_B = norm_B, cosine_similarity = cosine_similarity)
#> $dot_product
#> [1] 32
#> 
#> $norm_A
#> [1] 3.741657
#> 
#> $norm_B
#> [1] 8.774964
#> 
#> $cosine_similarity
#> [1] 0.9746318
```

### Pearson Correlation Coefficient

Pearson Correlation Coefficient adalah ukuran statistik yang digunakan untuk menentukan tingkat kemiripan atau hubungan linear antara dua variabel numerik. Koefisien ini memiliki nilai dalam rentang $[-1,1]$, di mana nilai $+1$ menunjukkan hubungan positif sempurna, $0$ menandakan tidak ada hubungan linear, dan $-1$ menunjukkan hubungan negatif sempurna. Dalam konteks analisis kemiripan, Pearson Correlation mengukur sejauh mana perubahan pada satu variabel berhubungan secara proporsional dengan perubahan pada variabel lainnya. Koefisien ini dihitung menggunakan rumus yang membandingkan kovarians dari dua variabel dengan hasil kali standar deviasi masing-masing variabel. Nilai yang mendekati $+1$ menunjukkan pola yang serupa antara dua variabel, sedangkan nilai mendekati $-1$ menunjukkan pola yang berlawanan. Pearson Correlation banyak digunakan dalam berbagai bidang, termasuk analisis cluster dan machine learning

Rumus untuk menghitung Pearson Correlation Coefficient antara dua variabel $X$ dan $Y$ adalah sebagai berikut:

$$
r = \frac{n(\sum XY) - (\sum X)(\sum Y)}{\sqrt{[n \sum X^2 - (\sum X)^2][n \sum Y^2 - (\sum Y)^2]}}
$$

Di mana:

-   $n$ adalah jumlah pasangan data,

-   $\sum XY$ adalah jumlah hasil kali dari setiap pasangan data,

-   $\sum X$ dan $\sum Y$ adalah jumlah dari masing-masing variabel,

-   $\sum X^2$ dan $\sum Y^2$ adalah jumlah kuadrat dari masing-masing variabel.

Misalkan kita memiliki dua variabel $X$ dan $Y$ dengan data sebagai berikut:

-   $X = \{1, 2, 3, 4 5\}$

-   $Y = \{2, 3, 5, 4, 5\}$

Langkah-langkah perhitungan Pearson Correlation Coefficient adalah sebagai berikut:

1.  Hitung jumlah $n$, $\sum X$, $\sum Y$, $\sum XY$, $\sum X^2$, dan $\sum Y^2$.
2.  Masukkan nilai-nilai tersebut ke dalam rumus Pearson Correlation Coefficient.

Langkah-langkah Perhitungan

-   $n = 5$

-   $\sum X = 1 + 2 + 3 + 4 + 5 = 15$

-   $\sum Y = 2 + 3 + 5 + 4 + 5 = 19$

-   $\sum XY = (1 \times 2) + (2 \times 3) + (3 \times 5) + (4 \times 4) + (5 \times 5) = 2 + 6 + 15 + 16 + 25 = 64$

-   $\sum X^2 = 1^2 + 2^2 + 3^2 + 4^2 + 5^2 = 1 + 4 + 9 + 16 + 25 = 55$

-   $\sum Y^2 = 2^2 + 3^2 + 5^2 + 4^2 + 5^2 = 4 + 9 + 25 + 16 + 25 = 79$

Masukkan ke dalam rumus: $$
  r = \frac{5(64) - (15)(19)}{\sqrt{[5(55) - (15)^2][5(79) - (19)^2]}}
  $$ $$
  r = \frac{320 - 285}{\sqrt{[275 - 225][395 - 361]}} = \frac{35}{\sqrt{50 \times  34}} = \frac{35}{\sqrt{1700}} \approx \frac{35}{41.23} \approx 0.848
  $$

**Contoh Penerapan earson Correlation Coefficient dengan R**


``` r
# Mendefinisikan data
X <- c(1, 2, 3, 4, 5)
Y <- c(2, 3, 5, 4, 5)

# Menghitung Pearson Correlation Coefficient
pearson_correlation <- cor(X, Y)

# Menampilkan hasil
pearson_correlation
#> [1] 0.8488747
```

### Extended Jaccard Similarity (Tanimoto Coefficient)

Extended Jaccard Similarity, juga dikenal sebagai Tanimoto Coefficient, adalah ukuran kesamaan antara dua set atau dua vektor. Ukuran ini digunakan untuk mengukur seberapa mirip dua objek berdasarkan elemen yang mereka miliki. Tanimoto Coefficient sering digunakan dalam analisis data, pengolahan citra, dan pengenalan pola. Rumus untuk menghitung Tanimoto Coefficient antara dua vektor $A$ dan $B$ adalah sebagai berikut:

$$
T(A, B) = \frac{|A \cap B|}{|A \cup B|} = \frac{a}{a + b + c}
$$

Di mana:

-   $|A \cap B|$ adalah jumlah elemen yang ada di kedua set (interseksi).

-   $|A \cup B|$ adalah jumlah elemen yang ada di set $A$ dan set $B$ (union).

-   $a$ adalah jumlah elemen yang sama di kedua set.

-   $b$ adalah jumlah elemen yang ada di set $A$ tetapi tidak di set $B$.

-   $c$ adalah jumlah elemen yang ada di set $B$ tetapi tidak di set $A$.

Nilai Tanimoto Coefficient berkisar antara 0 hingga 1:

-   **1**: Dua set identik (semua elemen sama).

-   **0**: Dua set tidak memiliki elemen yang sama.

Misalkan kita memiliki dua set:

-   $A = \{1, 2, 3, 4\}$

-   $B = \{3, 4, 5, 6\}$

Langkah-langkah perhitungan Tanimoto Coefficient adalah sebagai berikut:

1.  **Hitung interseksi** $|A \cap B|$:
    -   $|A \cap B| = \{3, 4\}$ → $a = 2$
2.  **Hitung union** $|A \cup B|$:
    -   $|A \cup B| = \{1, 2, 3, 4, 5, 6\}$ → $a + b + c = 6$
    -   Di mana $b = 2$ (elemen di $A$ tetapi tidak di $B$: $\{1, 2\}$) dan $c = 2$ (elemen di $B$ tetapi tidak di $A$: $\{5, 6\}$).
3.  **Hitung Tanimoto Coefficient**: $$
    T(A, B) = \frac{2}{6} \approx 0.333
    $$

**Contoh Penerapan Tanimoto Coefficient dengan R**


``` r
# Mendefinisikan dua set
A <- c(1, 2, 3, 4)
B <- c(3, 4, 5, 6)

# Menghitung interseksi dan union
intersection <- length(intersect(A, B))
union <- length(union(A, B))

# Menghitung Tanimoto Coefficient
tanimoto_coefficient <- intersection / union

# Menampilkan hasil
tanimoto_coefficient
#> [1] 0.3333333
```

### Dice Coefficient

Dice Coefficient, juga dikenal sebagai Dice Similarity Coefficient (DSC), adalah ukuran kesamaan antara dua set atau dua vektor. Ukuran ini sering digunakan dalam analisis data, pengolahan citra, dan pengenalan pola. Dice Coefficient memberikan bobot yang lebih besar pada elemen yang sama dibandingkan dengan ukuran kesamaan lainnya, seperti Jaccard Index. Rumus untuk menghitung Dice Coefficient antara dua set $A$ dan $B$ adalah sebagai berikut:

$$
D(A, B) = \frac{2|A \cap B|}{|A| + |B|}
$$

Di mana:

-   $|A \cap B|$ adalah jumlah elemen yang ada di kedua set (interseksi).

-   $|A|$ adalah jumlah elemen di set $A$.

-   $|B|$ adalah jumlah elemen di set $B$.

Nilai Dice Coefficient berkisar antara 0 hingga 1:

-   **1**: Dua set identik (semua elemen sama).

-   **0**: Dua set tidak memiliki elemen yang sama.

Misalkan kita memiliki dua set:

$A = \{1, 2, 3, 4\}$ -

$B = \{3, 4, 5, 6\}$

Langkah-langkah perhitungan Dice Coefficient adalah sebagai berikut:

1.  **Hitung interseksi** $|A \cap B|$:
    -   $|A \cap B| = \{3, 4\}$ → $|A \cap B| = 2$
2.  **Hitung ukuran set**:
    -   $|A| = 4$
    -   $|B| = 4$
3.  **Hitung Dice Coefficient**: $$
    D(A, B) = \frac{2 \times 2}{4 + 4} = \frac{4}{8} = 0.5
    $$

**Contoh Penerapan Dice Coefficient dengan R**


``` r
# Mendefinisikan dua set
A <- c(1, 2, 3, 4)
B <- c(3, 4, 5, 6)

# Menghitung interseksi
intersection <- length(intersect(A, B))

# Menghitung ukuran set
size_A <- length(A)
size_B <- length(B)

# Menghitung Dice Coefficient
dice_coefficient <- (2 * intersection) / (size_A + size_B)

# Menampilkan hasil
dice_coefficient
#> [1] 0.5
```

## Ukuran Ketidakmiripan

```{=html}
<style>
body{
text-align: justify}
</style>
```

### Jarak Euclidean

Jarak Euclidean adalah salah satu ukuran jarak yang paling umum digunakan dalam berbagai metode analisis data, termasuk dalam analisis cluster. Jarak ini mengukur seberapa jauh dua titik berada dalam ruang multidimensi. Secara intuitif, jarak Euclidean adalah "garis lurus" atau "jarak langsung" antara dua titik dalam ruang Euclidean, mirip dengan cara untuk mengukur jarak antara dua lokasi di dunia nyata menggunakan penggaris atau meteran [@everitt2011cluster].

Secara matematis, jika terdapat dua titik $P = (x_1, x_2, \dots, x_n)$ dan $Q = (y_1, y_2, \dots, y_n)$ dalam ruang $n$-dimensi, maka jarak Euclidean antara kedua titik tersebut dapat dihitung dengan rumus:

$$
d(P, Q) = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}
$$

Di mana:

-   $P = (x_1, x_2, \dots, x_n)$ adalah koordinat titik pertama,

-   $Q = (y_1, y_2, \dots, y_n)$ adalah koordinat titik kedua,

-   $d(P, Q)$ adalah jarak Euclidean antara titik $P$ dan titik $Q$,

-   $n$ adalah jumlah dimensi ruang (jumlah atribut yang digunakan dalam analisis).

Jarak Euclidean merupakan bentuk dari **norma L2** dalam ruang vektor. Norma ini mengukur panjang atau magnitudo dari sebuah vektor dalam ruang Euclidean. Dalam konteks data, kita bisa menganggap setiap titik sebagai vektor dalam ruang fitur, dan jarak Euclidean mengukur panjang vektor perbedaan antara dua titik tersebut.

Jarak ini juga terkait dengan konsep **teorema Pythagoras**, yang menyatakan bahwa dalam segitiga siku-siku, kuadrat panjang sisi miring (hipotenusa) sama dengan jumlah kuadrat panjang kedua sisi lainnya. Dalam konteks ruang dimensi lebih tinggi, kita memperluas teorema Pythagoras ke banyak dimensi.

Sebagai contoh, dalam ruang dua dimensi, jarak antara dua titik $P = (x_1, y_1)$ dan $Q = (x_2, y_2)$ adalah:

$$
d(P, Q) = \sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}
$$

Dalam ruang tiga dimensi, jarak Euclidean antara titik $P = (x_1, y_1, z_1)$ dan $Q = (x_2, y_2, z_2)$ adalah:

$$
d(P, Q) = \sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2 + (z_2 - z_1)^2}
$$

**Contoh Penerapan Jarak Euclidean dengan R**


``` r
# Menggunakan dataset contoh
data <- data.frame(
  X1 = c(1, 2, 3, 5),
  X2 = c(4, 6, 8, 10)
)

# Menghitung jarak Euclidean secara manual antara dua titik pertama
euclidean_distance <- function(a, b) {
  sqrt(sum((a - b)^2))
}

jarak <- euclidean_distance(data[1, ], data[2, ])
print(paste("Jarak Euclidean antara titik pertama dan kedua:", jarak))
#> [1] "Jarak Euclidean antara titik pertama dan kedua: 2.23606797749979"

# Menggunakan fungsi dist bawaan R untuk menghitung jarak antar semua titik
jarak_matrix <- dist(data, method = "euclidean")
print(jarak_matrix)
#>          1        2        3
#> 2 2.236068                  
#> 3 4.472136 2.236068         
#> 4 7.211103 5.000000 2.828427
```

### Jarak Minkowski

Jarak Minkowski adalah generalisasi dari berbagai metrik jarak yang digunakan untuk mengukur perbedaan atau kedekatan antara dua titik dalam ruang berdimensi $n$. Jarak ini berguna untuk atribut numerik dan mencakup beberapa metrik populer seperti Euclidean dan Manhattan sebagai kasus khususnya.

Jarak Minkowski antara dua titik $\mathbf{X} = (x_1, x_2, \ldots, x_n)$ dan $\mathbf{Y} = (y_1, y_2, \ldots, y_n)$ dalam ruang berdimensi $n$ didefinisikan sebagai:

$$
d(\mathbf{X}, \mathbf{Y}) = \left( \sum_{i=1}^n |x_i - y_i|^p \right)^{\frac{1}{p}}
$$

dimana:

-   $p$: parameter yang menentukan jenis metrik jarak,

-   $|x_i - y_i|$: nilai absolut dari perbedaan antara atribut ke-$i$ pada dua titik.

Dengan memilih nilai $p$ yang berbeda, kita mendapatkan metrik jarak berikut:

-   **Jarak Manhattan** ($p = 1$): $$
       d(\mathbf{X}, \mathbf{Y}) = \sum_{i=1}^n |x_i - y_i|
       $$ Jarak ini menghitung jumlah perbedaan absolut antara koordinat titik. Sering digunakan dalam kasus di mana pergerakan hanya memungkinkan secara horizontal dan vertikal, seperti grid kota.

-   **Jarak Euclidean** ($p = 2$): $$
       d(\mathbf{X}, \mathbf{Y}) = \sqrt{\sum_{i=1}^n (x_i - y_i)^2}
       $$

Metrik ini adalah jarak terpendek (garis lurus) antara dua titik dalam ruang Euclidean.

-   **Jarak Chebyshev** ($p \to \infty$): $$
       d(\mathbf{X}, \mathbf{Y}) = \max(|x_i - y_i|)
       $$

Jarak ini mempertimbangkan perbedaan maksimum di antara semua dimensi.


``` r
# Membuat dataset contoh
data <- data.frame(
  X1 = c(1, 2, 3, 5),
  X2 = c(4, 6, 8, 10)
)

# Fungsi untuk menghitung jarak Minkowski
minkowski_distance <- function(a, b, p) {
  sum(abs(a - b)^p)^(1/p)
}

# Contoh menghitung jarak Minkowski antara titik pertama dan kedua dengan p=3
jarak <- minkowski_distance(data[1, ], data[2, ], p = 3)
print(paste("Jarak Minkowski dengan p=3 antara titik pertama dan kedua:", jarak))
#> [1] "Jarak Minkowski dengan p=3 antara titik pertama dan kedua: 2.0800838230519"

# Menggunakan library proxy untuk menghitung jarak Minkowski antar semua titik
library(proxy)

# Menghitung jarak Minkowski dengan p=3 untuk semua titik
jarak_matrix <- dist(data, method = "Minkowski", p = 3)
print(jarak_matrix)
#>          1        2        3
#> 2 2.080084                  
#> 3 4.160168 2.080084         
#> 4 6.542133 4.497941 2.519842
```

### Pengukuran Jarak Atribut Biner

Dalam analisis cluster, pengukuran jarak antara objek dengan atribut biner (binary attributes) adalah langkah penting untuk menentukan seberapa mirip atau berbeda dua objek. Atribut biner adalah atribut yang hanya memiliki dua nilai, biasanya 0 dan 1, yang mewakili ketidakhadiran (0) atau kehadiran (1) suatu fitur.

**1. Jarak Jaccard (Jaccard Distance)** Jarak Jaccard digunakan untuk mengukur dissimilarity antara dua objek dengan atribut biner. Rumusnya adalah:

$$
d_{Jaccard}(A, B) = 1 - \frac{M_{11}}{M_{01} + M_{10} + M_{11}}
$$

Keterangan:

-   $M_{11}$: Jumlah atribut yang bernilai 1 untuk kedua objek.

-   $M_{01}$: Jumlah atribut yang bernilai 0 untuk objek A dan 1 untuk objek B.

-   $M_{10}$: Jumlah atribut yang bernilai 1 untuk objek A dan 0 untuk objek B.

**2. Jarak Hamming (Hamming Distance)** Jarak Hamming menghitung jumlah posisi di mana dua objek memiliki nilai yang berbeda. Rumusnya adalah:

$$
d_{Hamming}(A, B) = M_{01} + M_{10}
$$

Keterangan:

-   $M_{01}$: Jumlah atribut yang bernilai 0 untuk objek A dan 1 untuk objek B.

-   $M_{10}$: Jumlah atribut yang bernilai 1 untuk objek A dan 0 untuk objek B.

**Contoh Implementasi dengan R**

Berikut adalah contoh implementasi pengukuran jarak Jaccard dan Hamming menggunakan R:


``` r
# Contoh data biner
objek1 <- c(1, 0, 1, 0, 1)
objek2 <- c(1, 1, 0, 0, 0)

# Fungsi untuk menghitung Jarak Jaccard
jaccard_distance <- function(a, b) {
  M11 <- sum(a == 1 & b == 1)
  M01 <- sum(a == 0 & b == 1)
  M10 <- sum(a == 1 & b == 0)
  
  jarak <- 1 - (M11 / (M01 + M10 + M11))
  return(jarak)
}

# Fungsi untuk menghitung Jarak Hamming
hamming_distance <- function(a, b) {
  jarak <- sum(a != b)
  return(jarak)
}

# Menghitung jarak
jarak_jaccard <- jaccard_distance(objek1, objek2)
jarak_hamming <- hamming_distance(objek1, objek2)

# Menampilkan hasil
cat("Jarak Jaccard:", jarak_jaccard, "\n")
#> Jarak Jaccard: 0.75
cat("Jarak Hamming:", jarak_hamming, "\n")
#> Jarak Hamming: 3
```

### Pengukuran Jarak Atribut Kategorikal

Pengukuran jarak untuk atribut kategorikal digunakan untuk mengukur kesamaan atau perbedaan antara dua objek yang memiliki atribut berbentuk kategori. Contoh data kategorikal meliputi warna (merah, biru, hijau) atau tipe kendaraan (mobil, sepeda motor, sepeda). Tidak seperti atribut numerik atau biner, atribut kategorikal memerlukan pendekatan khusus karena tidak ada hubungan matematis langsung antara kategori.

Misalkan $\mathbf{X} = \{x_1, x_2, \dots, x_n\}$ dan $\mathbf{Y} = \{y_1, y_2, \dots, y_n\}$ adalah dua objek dengan $n$ atribut kategorikal. Beberapa metode jarak yang sering digunakan meliputi:

**1. Simple Matching Coefficient (SMC)** Koefisien Simple Matching mengukur kesamaan antara dua objek berdasarkan jumlah atribut yang cocok, baik sama-sama cocok atau sama-sama tidak cocok.

$$
S_{SMC}(\mathbf{X}, \mathbf{Y}) = \frac{m}{n}
$$ di mana $m$ adalah jumlah atribut di mana $x_i = y_i$, dan $n$ adalah jumlah total atribut.

$$
d_{SMC}(\mathbf{X}, \mathbf{Y}) = 1 - S_{SMC}(\mathbf{X}, \mathbf{Y})
$$

**2. Jarak Overlap** Jarak overlap menghitung kesamaan berdasarkan atribut yang cocok saja, tanpa memperhatikan atribut yang tidak cocok.

$$
d_{Overlap}(\mathbf{X}, \mathbf{Y}) = 1 - \frac{k}{n}
$$

di mana $k$ adalah jumlah atribut yang cocok ($x_i = y_i$).

**3. Goodall Similarity** Metode Goodall menggunakan probabilitas atribut untuk menentukan bobot kesamaan. Kesamaan dihitung berdasarkan probabilitas relatif dari kategori tertentu.

$$
S_{Goodall}(\mathbf{X}, \mathbf{Y}) = \frac{1}{n} \sum_{i=1}^n P(x_i)
$$ di mana $P(x_i)$ adalah probabilitas kategori $x_i$ dalam atribut ke-$i$.

**Implementasi Pengukuran Jarak di R**
Berikut adalah implementasi beberapa pengukuran jarak untuk atribut kategorikal:


``` r
# Contoh data kategorikal
X <- c("Merah", "Biru", "Hijau", "Kuning", "Biru")
Y <- c("Biru", "Biru", "Hijau", "Kuning", "Merah")

# Fungsi untuk menghitung Simple Matching Coefficient (SMC)
simple_matching <- function(x, y) {
  m <- sum(x == y) # Jumlah atribut yang cocok
  n <- length(x)   # Jumlah total atribut
  similarity <- m / n
  distance <- 1 - similarity
  return(list(Similarity = similarity, Distance = distance))
}

# Fungsi untuk menghitung Jarak Overlap
overlap_distance <- function(x, y) {
  k <- sum(x == y) # Jumlah atribut yang cocok
  n <- length(x)   # Jumlah total atribut
  distance <- 1 - (k / n)
  return(distance)
}

# Fungsi untuk menghitung Goodall Similarity
goodall_similarity <- function(x, y) {
  categories <- unique(c(x, y))
  prob <- table(c(x, y)) / length(c(x, y))
  similarity <- sum(prob[x == y]) / length(x)
  return(similarity)
}

# Perhitungan jarak
smc <- simple_matching(X, Y)
overlap <- overlap_distance(X, Y)

# Hasil perhitungan
print(smc)
#> $Similarity
#> [1] 0.6
#> 
#> $Distance
#> [1] 0.4
print(overlap)
#> [1] 0.4
```

### Pengukuran Jarak Atribut Campuran

Data sering kali memiliki atribut campuran, yaitu kombinasi dari atribut numerik, kategorikal, dan biner. Untuk mengukur jarak antara dua objek dalam data jenis ini, diperlukan metrik jarak yang mempertimbangkan perbedaan sifat atribut.

Misalkan ada dua objek $\mathbf{X}$ dan $\mathbf{Y}$ dengan $n$ atribut. Setiap atribut dapat berupa:

1.  **Numerik**: Memiliki nilai kontinu.

2.  **Kategorikal**: Memiliki nilai diskret tanpa hubungan matematis.

3.  **Biner**: Memiliki dua nilai, seperti 0 dan 1.

Metode pengukuran jarak untuk data campuran mengkombinasikan jarak antar atribut berdasarkan jenisnya.

**Heterogeneous Euclidean-Overlap Metric (HEOM)**

HEOM adalah salah satu metrik yang menggabungkan jarak Euclidean untuk atribut numerik dan jarak overlap untuk atribut kategorikal.

Untuk setiap atribut $i$, jarak dihitung sebagai:

$$
    d_i(x_i, y_i) =
    \begin{cases} 
    \frac{|x_i - y_i|}{r_i}, & \text{jika } x_i, y_i \text{ numerik} \\
    0, & \text{jika } x_i = y_i \text{ (kategorikal atau biner)} \\
    1, & \text{jika } x_i \neq y_i \text{ (kategorikal atau biner)} 
    \end{cases}
$$

di mana:

-   $r_i$ adalah rentang nilai maksimum dan minimum untuk atribut numerik $i$.

-   Jarak total diberikan oleh:

$$
  D(\mathbf{X}, \mathbf{Y}) = \sqrt{\sum_{i=1}^n d_i(x_i, y_i)^2}
$$

**Gower's Distance**

Gower's distance adalah metrik populer untuk atribut campuran. Untuk setiap atribut $i$:

$$
    s_i(x_i, y_i) =
    \begin{cases} 
    1 - \frac{|x_i - y_i|}{r_i}, & \text{jika } x_i, y_i \text{ numerik} \\
    1, & \text{jika } x_i = y_i \text{ (kategorikal atau biner)} \\
    0, & \text{jika } x_i \neq y_i \text{ (kategorikal atau biner)} 
    \end{cases}
$$

Koefisien kesamaan total adalah rata-rata:

$$
S(\mathbf{X}, \mathbf{Y}) = \frac{\sum_{i=1}^n w_i s_i(x_i, y_i)}{\sum_{i=1}^n w_i}
$$ 

di mana:

-   $w_i = 1$ jika $x_i$ dan $y_i$ memiliki nilai yang valid.

-   $w_i = 0$ jika salah satu $x_i$ atau $y_i$ adalah nilai yang hilang.

Jarak Gower adalah: 
$$
D_G(\mathbf{X}, \mathbf{Y}) = 1 - S(\mathbf{X}, \mathbf{Y})
$$
**Contoh Implementasi dengan R**


``` r
#Contoh data campuran
X <- data.frame(
  Numerik = c(5.5, 3.2),
  Kategorikal = c("A", "B"),
  Biner = c(1, 0)
)
Y <- data.frame(
  Numerik = c(6.3, 3.2),
  Kategorikal = c("A", "A"),
  Biner = c(1, 1)
)

#Fungsi HEOM
heom_distance <- function(x, y) {
  n <- ncol(x)
  distance <- numeric(n)
  
  for (i in 1:n) {
    if (is.numeric(x[[i]]) && is.numeric(y[[i]])) {
      r <- max(x[[i]], y[[i]]) - min(x[[i]], y[[i]])
      distance[i] <- abs(x[[i]] - y[[i]]) / r
    } else {
      distance[i] <- ifelse(x[[i]] == y[[i]], 0, 1)
    }
  }
  
  return(sqrt(sum(distance^2)))
}

#Fungsi Gower's Distance
gower_distance <- function(x, y) {
  n <- ncol(x)
  similarity <- numeric(n)
  weights <- numeric(n)
  
  for (i in 1:n) {
    if (is.numeric(x[[i]]) && is.numeric(y[[i]])) {
      r <- max(x[[i]], y[[i]]) - min(x[[i]], y[[i]])
      similarity[i] <- 1 - abs(x[[i]] - y[[i]]) / r
      weights[i] <- 1
    } else {
      similarity[i] <- ifelse(x[[i]] == y[[i]], 1, 0)
      weights[i] <- 1
    }
  }
  
  weighted_similarity <- sum(weights * similarity) / sum(weights)
  return(1 - weighted_similarity)
}

#Hitung jarak
heom <- heom_distance(X, Y)
gower <- gower_distance(X, Y)

#Hasil perhitungan
cat("HEOM Distance:", heom, "\n")
#> HEOM Distance: 0.2580645
cat("Gower's Distance:", gower, "\n")
#> Gower's Distance: 0.08602151
```

